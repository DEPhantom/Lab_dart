import sklearn.metrics
from sklearn import datasets
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import math
import numpy as np
import pandas as pd


class Node:
    "Decision tree node"
    def __init__(self, entropy, num_samples, num_samples_per_class, predicted_class, num_errors, alpha=float("inf")):
        self.entropy = entropy # the entropy of current node
        self.num_samples = num_samples
        self.num_samples_per_class = num_samples_per_class
        self.predicted_class = predicted_class # the majority class of the split group
        self.feature_index = 0 # the feature index we used to split the node
        self.threshold = 0 # for binary split
        self.left = None # left child node
        self.right = None # right child node
        self.num_errors = num_errors # error after cut
        self.alpha = alpha # each node alpha


class DecisionTreeClassifier:
    def __init__(self, max_depth=4):
        self.root = None
        self.max_depth = max_depth
        self.n_classes_ = 0

    def _spilt_data(self, X, y, idx, thr ):
      true_data_x = []
      true_data_y = []
      false_data_x = []
      false_data_y = []
      for i in range( len(X) ):
        if ( X[i][idx] == thr ):
          true_data_x.append( X[i] )
          true_data_y.append( y[i] )
        else :
          false_data_x.append( X[i] )
          false_data_y.append( y[i] )
          
      # end for
        
      return true_data_x, true_data_y, len(set(true_data_y)), false_data_x, false_data_y, len(set(false_data_y))
      
    # end _spilt_data()

    def _entropy(self, sample_y, n_classes):
        # TODO: calculate the entropy of sample_y and return it
        # sample_y represent the label of node
        # entropy = -sum(pi * log2(pi))
        entropy = 0
        summary_y = []
        sum_y = 0
        for i in range(n_classes) :
          for j in range( len(sample_y) ) :
            if ( sample_y[j] == i ):
              sum_y = sum_y+1
          # end for
          
          summary_y.append( sum_y )
          sum_y = 0
          
        # end for

        total = len( sample_y )
        for i in range( n_classes ):
          if ( summary_y[i] != 0 ) :
            entropy = entropy+((-summary_y[i]/total)*math.log(summary_y[i]/total,2))
          # end if
          else : # log 0
            entropy = entropy+0
          # end else
          
        # end for
        
        return entropy
        
    # end _entropy()

    def _feature_split(self, X, y, n_classes):
        X_transfer = list(zip(*X)) # list of tuple
        X_transfer_summary = []
        true_data_x = []
        true_data_y = []
        true_n_classes = 0
        false_data_x = []
        false_data_y = [] 
        false_n_classes = 0
        # Returns:
        #  best_idx: Index of the feature for best split, or None if no split is found.
        #  best_thr: Threshold to use for the split, or None if no split is found.
        m = y.size
        if m <= 1:
            return None, None

        # Entropy of current node.

        best_criterion = self._entropy(y, n_classes)

        best_idx, best_thr = None, None
        # TODO: find the best split, loop through all the features, and consider all the
        # midpoints between adjacent training samples as possible thresholds. 
        # Compute the Entropy impurity of the split generated by that particular feature/threshold
        # pair, and return the pair with smallest impurity.
        for col in range( len(X[0]) ):
          X_transfer_summary = list( set(X_transfer[col]) )
          for loc in range( len(X_transfer_summary) ):
              true_data_x, true_data_y, true_n_classes, false_data_x, false_data_y, false_n_classes = self._spilt_data( X, y, col, X_transfer_summary[loc] )
              temp_entropy = (len(true_data_y)/(len(true_data_y)+len(false_data_y)))*self._entropy( true_data_y, true_n_classes )+(len(false_data_y)/(len(true_data_y)+len(false_data_y)))*self._entropy( false_data_y, false_n_classes ) 
              if ( temp_entropy < best_criterion ) :
                best_idx = col
                best_thr = X_transfer_summary[loc]
                best_criterion = temp_entropy
              # end if
              
          # end for
          
        # end for


        return best_idx, best_thr
        
    # end _feature_split()
        
        
    def _build_tree(self, X, y, depth=0):
        true_data_x = []
        true_data_y = []
        true_n_classes = 0
        false_data_x = []
        false_data_y = [] 
        false_n_classes = 0
        
        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]
        predicted_class = np.argmax(num_samples_per_class)
        correct_label_num = num_samples_per_class[predicted_class]
        num_errors = y.size - correct_label_num
        node = Node(
            entropy = self._entropy(y,self.n_classes_),
            num_samples=y.size,
            num_samples_per_class=num_samples_per_class,
            predicted_class=predicted_class,
            num_errors=num_errors
        )

        if depth < self.max_depth:
            idx, thr = self._feature_split(X, y, self.n_classes_)
            if idx is not None:
            # TODO: Split the tree recursively according index and threshold until maximum depth is reached.
                true_data_x, true_data_y, true_n_classes, false_data_x, false_data_y, false_n_classes = self._spilt_data( X, y, idx, thr )
                node.feature_index = idx
                node.threshold = thr
                node.left = self._build_tree( true_data_x, np.array(true_data_y), depth+1 )
                node.right = self._build_tree( false_data_x, np.array(false_data_y), depth+1 )

            # end if
            else : # can not spilt anymore
              node.feature_index = -1
            # end else
            
        # end if
        else :
          return None # depth is out of range
        # end else

        return node
        
    # end _build_tree()

    def print_tree( self, node, depth ):
    
      if ( node != None ):
        print( node.feature_index, end=" " )
        print( node.threshold )
        print( "predict:", end=" " )
        print( node.predicted_class, end=" " )
        print( depth )
        print( "left is" )
        self.print_tree( node.left, depth+1 )
        print( "right is" )
        self.print_tree( node.right, depth+1 )
        
    # end print_tree()

    def fit(self,X,Y):
        # TODO
        # Fits to the given training data
        self.n_classes_ = len(set(Y))
        self.root = self._build_tree( X, Y, 0 )
        self.print_tree( self.root, 0 )
        print( "------------------------------------------------" )
        
    # end fit()

    def predict(self,X):
        pred = []
        temp_node = self.root
        find = False
        #TODO: predict the label of data
        for i in range(len(X)) :
          while( temp_node != None and not find ):
          
            if ( temp_node.left == None and temp_node.right == None ) :
              find = True
            # end if
            elif ( temp_node.feature_index == -1 ) :
              find = True
            # end elif
            elif ( X[i][temp_node.feature_index] == temp_node.threshold ):
              temp_node = temp_node.left
            # end else
            else:
              temp_node = temp_node.right
            # end else
            
          # end while()
          
          if ( find ) :
            pred.append( temp_node.predicted_class )
          # end if
          else :
            pred.append( 0 )
          # end else
          
        # end for
        
        return pred
        
    # end predict()

    def _find_leaves(self, root):
        #TODO
        ## find each node child leaves number
        left_leaves = 0
        right_leaves = 0
        if ( root.left != None ):
          left_leaves = self._find_leaves( root.left )
        # end if
        if ( root.right != None ):
          right_leaves = self._find_leaves( root.right )
        # end else
        
        if ( left_leaves+right_leaves == 0 ) :
          return 1
        # end if
        else :
          return left_leaves+right_leaves
        # end else
        
    # end _find_leaves()
    
    def _error_before_cut(self, root):
        # TODO
        left_error = 0
        right_error = 0
        if ( root.left != None ):
          left_error = self._error_before_cut( root.left )
        # end if
        if ( root.right != None ):
          right_error = self._error_before_cut( root.right )
        # end else
        
        if ( left_error+right_error == 0 ) :
          return root.num_errors
        # end if
        else :
          return left_error+right_error
        # end else
        
    # end _error_before_cut()

    def _compute_alpha(self, root):
        # TODO
        ## Compute each node alpha
        # alpha = (error after cut - error before cut) / (leaves been cut - 1)
        alpha = ( root.num_errors - self._error_before_cut( root ) ) / ( self._find_leaves(root)-1 )
        return alpha
        
    # end _compute_alpha()
    
    def _find_min_alpha(self, root):
        MinAlpha = float("inf")
        left_node = None
        left_smallest_alpha = 0
        right_node = None
        right_smallest_alpha = 0
        
        # TODO
        ## Search the Decision tree which have minimum alpha's node
        if ( root.left == None and root.right == None ) : # leave
          return root, float("inf")
        # end if
        
        root.alpha = self._compute_alpha(root)
        if ( root.left != None ) :
          left_node, left_smallest_alpha = self._find_min_alpha(root.left)
        # end if
        else :
          left_smallest_alpha = float("inf")
        # end else
        
        if ( root.right != None ) :
          right_node, right_smallest_alpha = self._find_min_alpha(root.right)
        # end if
        else :
          right_smallest_alpha = float("inf")
        # end else
        
        if ( left_smallest_alpha <= root.alpha and left_smallest_alpha <= right_smallest_alpha ) :
          return left_node, left_smallest_alpha
        # end if
        elif ( right_smallest_alpha <= root.alpha and right_smallest_alpha <= left_smallest_alpha ):
          return right_node, right_smallest_alpha
        # end elif
        elif ( root.alpha < left_smallest_alpha and root.alpha < right_smallest_alpha ) :
          return root, root.alpha
        # end elif
        else:
          return root, root.alpha
        # end else
        
    # end _compute_alpha()
    
    def _prune_tree(self, root, smallest_node):
      if ( root == None ):
        return None
      # end if
      elif( root == smallest_node ):
        root.left = None
        root.right = None
        return root
      # end elif
      else:
        root.left = self._prune_tree(root.left, smallest_node)
        root.right = self._prune_tree(root.right, smallest_node)
        return root
      # end else
    
    # end _prune_tree()

    def _prune(self):
        # TODO
        # prune the decision tree with minimum alpha node
        MinAlpha = float("inf")
        smallest_node = None
        if ( self.root != None ) :
          smallest_node, MinAlpha = self._find_min_alpha(self.root)
        # end if
        
        self.root = self._prune_tree(self.root, smallest_node)
        
    # end _prune()


def load_train_test_data(test_ratio=.3, random_state = 1):
    df = pd.read_csv('./car.data', names=['buying', 'maint',
                     'doors', 'persons', 'lug_boot', 'safety', 'target'])
    X = df.drop(columns=['target'])
    X = np.array(X.values)
    y = np.array(df['target'].values)
    label = np.unique(y)
    # label encoding
    for i in range(len(y)):
        for j in range(len(label)):
            if y[i] == label[j]:
                y[i] = j
                break
    y = y.astype('int')
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size = test_ratio, random_state=random_state, stratify=y)
    return X_train, X_test, y_train, y_test


def accuracy_report(X_train_scale, y_train,X_test_scale,y_test,max_depth=7):
    tree = DecisionTreeClassifier( max_depth=max_depth )
    tree.fit(X_train_scale, y_train)
    pred = tree.predict(X_train_scale)

    print(" tree train accuracy: %f" 
        % (sklearn.metrics.accuracy_score(y_train, pred )))
    pred = tree.predict(X_test_scale)
    print(" tree test accuracy: %f" 
        % (sklearn.metrics.accuracy_score(y_test, pred )))

    for i in range(10):
        print("=============Cut=============")
        tree._prune()
        pred = tree.predict(X_train_scale)
        print(" tree train accuracy: %f"
              % (sklearn.metrics.accuracy_score(y_train, pred)))
        pred = tree.predict(X_test_scale)
        print(" tree test accuracy: %f"
              % (sklearn.metrics.accuracy_score(y_test, pred)))
    

def main():
    X_train, X_test, y_train, y_test = load_train_test_data(test_ratio=.3,random_state = 1)
    # accuracy_report(X_train, y_train,X_test,y_test,max_depth=8)
    accuracy_report(X_train, y_train,X_test,y_test,max_depth=4)


if __name__ == "__main__":
    main()